{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_generator(generator_inputs, generator_outputs_channels):\n",
    "    layers = []\n",
    "\n",
    "    # encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]\n",
    "    with tf.variable_scope(\"encoder_1\"):\n",
    "        output = conv(generator_inputs, a.ngf, stride=2)\n",
    "        layers.append(output)\n",
    "\n",
    "    layer_specs = [\n",
    "        a.ngf * 2, # encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]\n",
    "        a.ngf * 4, # encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]\n",
    "        a.ngf * 8, # encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]\n",
    "        a.ngf * 8, # encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]\n",
    "        a.ngf * 8, # encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]\n",
    "        a.ngf * 8, # encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]\n",
    "        a.ngf * 8, # encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]\n",
    "    ]\n",
    "\n",
    "    for out_channels in layer_specs:\n",
    "        with tf.variable_scope(\"encoder_%d\" % (len(layers) + 1)):\n",
    "            rectified = lrelu(layers[-1], 0.2)\n",
    "            # [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]\n",
    "            convolved = conv(rectified, out_channels, stride=2)\n",
    "            output = batchnorm(convolved)\n",
    "            layers.append(output)\n",
    "\n",
    "    layer_specs = [\n",
    "        (a.ngf * 8, 0.5),   # decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]\n",
    "        (a.ngf * 8, 0.5),   # decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]\n",
    "        (a.ngf * 8, 0.5),   # decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]\n",
    "        (a.ngf * 8, 0.0),   # decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]\n",
    "        (a.ngf * 4, 0.0),   # decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]\n",
    "        (a.ngf * 2, 0.0),   # decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]\n",
    "        (a.ngf, 0.0),       # decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]\n",
    "    ]\n",
    "\n",
    "    num_encoder_layers = len(layers)\n",
    "    for decoder_layer, (out_channels, dropout) in enumerate(layer_specs):\n",
    "        skip_layer = num_encoder_layers - decoder_layer - 1\n",
    "        with tf.variable_scope(\"decoder_%d\" % (skip_layer + 1)):\n",
    "            if decoder_layer == 0:\n",
    "                # first decoder layer doesn't have skip connections\n",
    "                # since it is directly connected to the skip_layer\n",
    "                input = layers[-1]\n",
    "            else:\n",
    "                input = tf.concat([layers[-1], layers[skip_layer]], axis=3)\n",
    "\n",
    "            rectified = tf.nn.relu(input)\n",
    "            # [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]\n",
    "            output = deconv(rectified, out_channels)\n",
    "            output = batchnorm(output)\n",
    "\n",
    "            if dropout > 0.0:\n",
    "                output = tf.nn.dropout(output, keep_prob=1 - dropout)\n",
    "\n",
    "            layers.append(output)\n",
    "\n",
    "    # decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]\n",
    "    with tf.variable_scope(\"decoder_1\"):\n",
    "        input = tf.concat([layers[-1], layers[0]], axis=3)\n",
    "        rectified = tf.nn.relu(input)\n",
    "        output = deconv(rectified, generator_outputs_channels)\n",
    "        output = tf.tanh(output)\n",
    "        layers.append(output)\n",
    "\n",
    "    return layers[-1]\n",
    "\n",
    "\n",
    "def create_model(inputs, targets):\n",
    "    def create_discriminator(discrim_inputs, discrim_targets):\n",
    "        n_layers = 3\n",
    "        layers = []\n",
    "\n",
    "        # 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]\n",
    "        input = tf.concat([discrim_inputs, discrim_targets], axis=3) # images will be of axis= 2 with 3 channels ,concatenation of two images gets axis = 3\n",
    "\n",
    "        # layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]\n",
    "        with tf.variable_scope(\"layer_1\"):\n",
    "            convolved = conv(input, a.ndf, stride=2) \n",
    "            rectified = lrelu(convolved, 0.2)\n",
    "            layers.append(rectified) # first layer for discriminator with the number of discriminator filters given in the argument\n",
    "\n",
    "        # layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]\n",
    "        # layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]\n",
    "        # layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]\n",
    "        for i in range(n_layers):\n",
    "            with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "                out_channels = a.ndf * min(2**(i+1), 8)\n",
    "                stride = 1 if i == n_layers - 1 else 2  # last layer here has stride 1\n",
    "                convolved = conv(layers[-1], out_channels, stride=stride)\n",
    "                normalized = batchnorm(convolved)\n",
    "                rectified = lrelu(normalized, 0.2)\n",
    "                layers.append(rectified) #introduce more layers and can construct a deep conv net\n",
    "\n",
    "        # layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]\n",
    "        with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "            convolved = conv(rectified, out_channels=1, stride=1)\n",
    "            output = tf.sigmoid(convolved)\n",
    "            layers.append(output) # Final layer should have stride 1 \n",
    "\n",
    "        return layers[-1] # returns final layer\n",
    "\n",
    "    with tf.variable_scope(\"generator\") as scope:\n",
    "        out_channels = int(targets.get_shape()[-1]) \n",
    "        outputs = create_generator(inputs, out_channels)\n",
    "\n",
    "    # create two copies of discriminator, one for real pairs and one for fake pairs\n",
    "    # they share the same underlying variables\n",
    "    with tf.name_scope(\"real_discriminator\"):\n",
    "        with tf.variable_scope(\"discriminator\"):\n",
    "            # 2x [batch, height, width, channels] => [batch, 30, 30, 1]\n",
    "            predict_real = create_discriminator(inputs, targets)\n",
    "\n",
    "    with tf.name_scope(\"fake_discriminator\"):\n",
    "        with tf.variable_scope(\"discriminator\", reuse=True):\n",
    "            # 2x [batch, height, width, channels] => [batch, 30, 30, 1]\n",
    "            predict_fake = create_discriminator(inputs, outputs)\n",
    "\n",
    "    with tf.name_scope(\"discriminator_loss\"):\n",
    "        # minimizing -tf.log will try to get inputs to 1\n",
    "        # predict_real => 1\n",
    "        # predict_fake => 0\n",
    "        discrim_loss = tf.reduce_mean(-(tf.log(predict_real + EPS) + tf.log(1 - predict_fake + EPS))) #EPS =1e-12 if predict_real=0 the log will not exist\n",
    "\n",
    "    with tf.name_scope(\"generator_loss\"):\n",
    "        # predict_fake => 1\n",
    "        # abs(targets - outputs) => 0\n",
    "\n",
    "        gen_loss_GAN = tf.reduce_mean(-tf.log(predict_fake + EPS)) \n",
    "        gen_loss_L1 = tf.reduce_mean(tf.abs(targets - outputs)) # L1 loss to make the output more related to image and L2 loss is avoided to avoid blur.\n",
    "        gen_loss = gen_loss_GAN * a.gan_weight + gen_loss_L1 * a.l1_weight #a.l1_weight is a constant equal to 100 that multplies the l1 loss\n",
    "\n",
    "\n",
    "    with tf.name_scope(\"discriminator_train\"):\n",
    "        discrim_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\n",
    "        discrim_optim = tf.train.AdamOptimizer(a.lr, a.beta1)\n",
    "        discrim_grads_and_vars = discrim_optim.compute_gradients(discrim_loss, var_list=discrim_tvars)\n",
    "        discrim_train = discrim_optim.apply_gradients(discrim_grads_and_vars)\n",
    "\n",
    "    with tf.name_scope(\"generator_train\"):\n",
    "        with tf.control_dependencies([discrim_train]):\n",
    "            gen_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\n",
    "            gen_optim = tf.train.AdamOptimizer(a.lr, a.beta1)\n",
    "            gen_grads_and_vars = gen_optim.compute_gradients(gen_loss, var_list=gen_tvars)\n",
    "            gen_train = gen_optim.apply_gradients(gen_grads_and_vars)\n",
    "\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.99)\n",
    "    update_losses = ema.apply([discrim_loss, gen_loss_GAN, gen_loss_L1])\n",
    "\n",
    "    global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "    incr_global_step = tf.assign(global_step, global_step+1)\n",
    "\n",
    "    return Model(\n",
    "        predict_real=predict_real,\n",
    "        predict_fake=predict_fake,\n",
    "        discrim_loss=ema.average(discrim_loss),\n",
    "        discrim_grads_and_vars=discrim_grads_and_vars,\n",
    "        gen_loss_GAN=ema.average(gen_loss_GAN),\n",
    "        gen_loss_L1=ema.average(gen_loss_L1),\n",
    "        gen_grads_and_vars=gen_grads_and_vars,\n",
    "        outputs=outputs,\n",
    "        train=tf.group(update_losses, incr_global_step, gen_train),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}